{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e37288",
   "metadata": {},
   "source": [
    "# SemEval 2021 Task 5: Toxic Spans Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b68554",
   "metadata": {},
   "source": [
    "### Research & Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb8d18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from plotnine import *\n",
    "from pytorch_lightning import (\n",
    "    LightningModule,\n",
    "    LightningDataModule,\n",
    "    Trainer,\n",
    "    seed_everything,\n",
    ")\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "from transformers import MobileBertTokenizerFast, MobileBertForTokenClassification\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "random.seed(a=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c444a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_df(df: pd.DataFrame, n: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Helper method to easily inspect DataFrames.\"\"\"\n",
    "\n",
    "    print(f\"shape: {df.shape}\")\n",
    "\n",
    "    return df.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2173f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.getcwd().split(\"toxic-spans-detection\")[0] + \"toxic-spans-detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342be792",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [A First Baseline](#A-First-Baseline)\n",
    "- [As a Downstream Task](#As-a-Downstream-Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff85e02",
   "metadata": {},
   "source": [
    "Our [objective](https://competitions.codalab.org/competitions/25623#learn_the_details-overview) here is to train a suitable model that will be able to predict the toxic spans -if any- contained in new, unseen documents.\n",
    "\n",
    "We will treat this as a binary sequence labelling task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9894cfb2",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f485287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7939, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>Another violent and aggressive immigrant killing a innocent and intelligent US Citizen.... Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junior pal. What you are saying makes no sense. I don't know what you are basing this on. The cheap black market crap is still coming up from Mexican nationals, and the good stuff from BC and Humbolt.  The I5 corridor is still just as busy, and they are still making a ton of money. Nothing has really changed except that the legal market has made it easy for anyone of legal age to buy it.  And the legal market is controlled by corporate growers with million dollar facilities, or a co-op of smaller growers. The Federal government \"war on drugs\" really has no impact on the legal market in Oregon. I don't see any glutton of weed, whatever that means.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know this would be offensive??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nAnyone and everyone. This is a community problem, so everyone who wants to be part of the solution should be allowed to help. As I said above: remove all protections on free ranging cats, and allow people to help. People who allow their pets to roam outside are part of the problem, because their pets are part of the problem. It would be very sad if pets were killed, but ultimately it is the owner's responsibility to make sure their pets are not out killing birds.\\n\\nYears ago some Vermont acquaintances got one warning from the Ranger: Next time I see your dog running deer, I'll shoot it. Next time she saw it running deer, she did. \\n\\nVermont does not pretend that trapping, neutering, and releasing dogs solves any problems. They are serious about threats. We just want to feel good about ourselves. If we were serious about feral cats, we would kill them. Neutered cats eat birds. Don't release them. Kill them.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                            spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]   \n",
       "1                                                                                                    [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                                                                                                    [0, 1, 2, 3]   \n",
       "3                                                                                       [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                                                                                                    [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Another violent and aggressive immigrant killing a innocent and intelligent US Citizen.... Sarcasm  \n",
       "1                                                                                                                                                                                                                                                                                 I am 56 years old, I am not your fucking junior pal. What you are saying makes no sense. I don't know what you are basing this on. The cheap black market crap is still coming up from Mexican nationals, and the good stuff from BC and Humbolt.  The I5 corridor is still just as busy, and they are still making a ton of money. Nothing has really changed except that the legal market has made it easy for anyone of legal age to buy it.  And the legal market is controlled by corporate growers with million dollar facilities, or a co-op of smaller growers. The Federal government \"war on drugs\" really has no impact on the legal market in Oregon. I don't see any glutton of weed, whatever that means.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Damn, a whole family. Sad indeed.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   What a knucklehead. How can anyone not know this would be offensive??  \n",
       "4  \"who do you think should do the killing?\"\\n\\nAnyone and everyone. This is a community problem, so everyone who wants to be part of the solution should be allowed to help. As I said above: remove all protections on free ranging cats, and allow people to help. People who allow their pets to roam outside are part of the problem, because their pets are part of the problem. It would be very sad if pets were killed, but ultimately it is the owner's responsibility to make sure their pets are not out killing birds.\\n\\nYears ago some Vermont acquaintances got one warning from the Ranger: Next time I see your dog running deer, I'll shoot it. Next time she saw it running deer, she did. \\n\\nVermont does not pretend that trapping, neutering, and releasing dogs solves any problems. They are serious about threats. We just want to feel good about ourselves. If we were serious about feral cats, we would kill them. Neutered cats eat birds. Don't release them. Kill them.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "\n",
    "trainset = pd.read_csv(os.path.join(DATA_DIR, \"tsd_train.csv\"))\n",
    "\n",
    "inspect_df(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0725e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_spans(spans: pd.Series) -> pd.Series:\n",
    "\n",
    "    try:\n",
    "        return spans.apply(literal_eval)\n",
    "\n",
    "    except ValueError as exc:  # in case cell is executed more than once\n",
    "        print(str(exc))\n",
    "        return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "383eb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will deserialize spans from strings to proper objects (lists)\n",
    "trainset[\"spans\"] = deserialize_spans(trainset[\"spans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5d558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data points contain toxic spans?\n",
    "toxic = trainset[\"spans\"].apply(len) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72365b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8739866165017)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    ggplot()\n",
    "    + geom_bar(mapping=aes(x=toxic), colour=\"white\")\n",
    "    + labs(title=\"text contains toxic spans ?\", x=\"\")\n",
    "    + coord_flip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e5a0679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (485, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "      <td>But, but, but, is NOT a defense.  It's not even a good deflection.  In America today we have Nazis waving the Nazi flag at rallies in our cities. In what capacity does anyone think this is ok and who would not see that as a problem?\\n\\nEnough with the \"Well what about blah blah\" garbage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[]</td>\n",
       "      <td>Jim\\n\\nI think Donald is a con man and a dangerous, narcissistic buffoon. But I don't hate Donald.  He's not worth the emotional effort needed to hate. To say I hate him is to admit that I even care about him, which I don't. What I do care about is the damage he's already caused to this country, and the continuing damage he'll cause to this country and the world until he leaves office.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[]</td>\n",
       "      <td>Exposing hypocrites like Trump and Pence is therapeutic for you? Good job!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[]</td>\n",
       "      <td>The malignant narcissist, mentally deranged sociopath, bigot, rascist, disingenuous blowhard and pathological liar, has now certified himself as a fascist. How much longer before his GOP sycophants and suckees say, \"Enough!\", and demand this repugnant, excrement-spewing fool's ouster?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[]</td>\n",
       "      <td>the is NO CONSENSUS you ignorant loser, NONE, nothing but debate, thousands of scientist do not agree period, we dont need to move from anything other than left wing stupidity like yours.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spans  \\\n",
       "5     []   \n",
       "21    []   \n",
       "24    []   \n",
       "27    []   \n",
       "60    []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                    text  \n",
       "5                                                                                                       But, but, but, is NOT a defense.  It's not even a good deflection.  In America today we have Nazis waving the Nazi flag at rallies in our cities. In what capacity does anyone think this is ok and who would not see that as a problem?\\n\\nEnough with the \"Well what about blah blah\" garbage.  \n",
       "21  Jim\\n\\nI think Donald is a con man and a dangerous, narcissistic buffoon. But I don't hate Donald.  He's not worth the emotional effort needed to hate. To say I hate him is to admit that I even care about him, which I don't. What I do care about is the damage he's already caused to this country, and the continuing damage he'll cause to this country and the world until he leaves office.  \n",
       "24                                                                                                                                                                                                                                                                                                                            Exposing hypocrites like Trump and Pence is therapeutic for you? Good job!  \n",
       "27                                                                                                         The malignant narcissist, mentally deranged sociopath, bigot, rascist, disingenuous blowhard and pathological liar, has now certified himself as a fascist. How much longer before his GOP sycophants and suckees say, \"Enough!\", and demand this repugnant, excrement-spewing fool's ouster?  \n",
       "60                                                                                                                                                                                                           the is NO CONSENSUS you ignorant loser, NONE, nothing but debate, thousands of scientist do not agree period, we dont need to move from anything other than left wing stupidity like yours.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some non-toxic documents\n",
    "inspect_df(trainset[~toxic])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4edcc",
   "metadata": {},
   "source": [
    "We can observe that, although these `485` texts do not have toxic spans as annotation, some of them clearly contain toxic words, phrases etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773a3dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7939.000000\n",
       "mean      204.570601\n",
       "std       201.369223\n",
       "min         4.000000\n",
       "25%        72.000000\n",
       "50%       136.000000\n",
       "75%       262.000000\n",
       "max      1000.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[\"text\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c57f45",
   "metadata": {},
   "source": [
    "The average document in the training dataset has `204` characters, the shortest one is only `4` characters while the largest one is `1000`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8183ba24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7454.000000\n",
       "mean       18.663134\n",
       "std        46.955908\n",
       "min         2.000000\n",
       "25%         6.000000\n",
       "50%         9.000000\n",
       "75%        16.000000\n",
       "max       994.000000\n",
       "Name: spans, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[toxic][\"spans\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09143099",
   "metadata": {},
   "source": [
    "The average toxic document in the training dataset has `~19` toxic characters (i.e. characters belonging to toxic character sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71168509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8739866138868)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    ggplot()\n",
    "    + geom_histogram(mapping=aes(x=trainset[\"text\"].map(len)), colour=\"white\", bins=30)\n",
    "    + xlab(\"toxic characters\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b82eb8",
   "metadata": {},
   "source": [
    "We can observe that in a typical span, let's say:\n",
    "\n",
    "$$ [ 3, 4, 5, 6, 44, 45, 46 ] $$\n",
    "\n",
    "groups of consequtive integers ($ 3 \\rightarrow 6, 44 \\rightarrow 46$) are basically individual character sequences.\n",
    "\n",
    "Based on that observation, we can also get a peek on the number of toxic character sequences in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20fb307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_spans(iterable: list):\n",
    "    \"\"\"Yield groups of continuous spans from an `iterable`.\n",
    "\n",
    "    Example:\n",
    "\n",
    "        iterable: [10, 11, 12, 13, 14, 15, 51, 52, 53, 54, 55, 56]\n",
    "\n",
    "        Returns: an iterator of groups. Each group is itself an iterator that materializes in a continuous span:\n",
    "                     1. [10, 11, 12, 13, 14, 15]\n",
    "                     2. [51, 52, 53, 54, 55, 56]\n",
    "\n",
    "    Inspired by: https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.consecutive_groups\n",
    "    \"\"\"\n",
    "    for _, g in groupby(enumerate(iterable), key=lambda x: x[0] - x[1]):\n",
    "        yield map(itemgetter(1), g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa4a30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "charsequences = trainset[toxic][\"spans\"].apply(\n",
    "    lambda s: [list(charseq) for charseq in continuous_spans(s)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab33f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7454.000000\n",
       "mean        1.381540\n",
       "std         0.791483\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        25.000000\n",
       "Name: spans, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charsequences.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2051bb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8739866113238)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    ggplot()\n",
    "    + geom_histogram(mapping=aes(x=charsequences.map(len)), colour=\"white\", bins=30)\n",
    "    + xlab(\"toxic character sequences\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71c597",
   "metadata": {},
   "source": [
    "So, a typical toxic document of the training dataset is likely to have 1 or 2 character sequences that attribute to its toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46279f0f",
   "metadata": {},
   "source": [
    "## A First Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5983d",
   "metadata": {},
   "source": [
    "We will establish an $ F_1 $ score, suitable for the representations of this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "550cabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(predictions, gold):\n",
    "    \"\"\"\n",
    "    F1 (a.k.a. DICE) operating on two lists of offsets (e.g., character).\n",
    "\n",
    "        >>> assert f1([0, 1, 4, 5], [0, 1, 6]) == 0.5714285714285714\n",
    "\n",
    "    :param predictions: a list of predicted offsets\n",
    "    :param gold: a list of offsets serving as the ground truth\n",
    "    :return: a score between 0 and 1\n",
    "\n",
    "    Originally in: https://github.com/ipavlopoulos/toxic_spans/blob/master/evaluation/semeval2021.py\n",
    "    \"\"\"\n",
    "    if len(gold) == 0:\n",
    "        return 1.0 if len(predictions) == 0 else 0.0\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    predictions_set = set(predictions)\n",
    "    gold_set = set(gold)\n",
    "\n",
    "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
    "    denom = len(predictions_set) + len(gold_set)\n",
    "\n",
    "    return float(nom) / float(denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27b96c",
   "metadata": {},
   "source": [
    "To better understand the complexity of this task, we will create a basic random sequence labeller and assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d644bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSequenceLabeller(object):\n",
    "    \"\"\"Random sequence labeller - returns toxic offsets at random.\"\"\"\n",
    "\n",
    "    def predict(self, doc: str) -> list:\n",
    "\n",
    "        return [i for i, ch in enumerate(doc) if random.random() > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28c494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the validation set\n",
    "validationset = pd.read_csv(os.path.join(DATA_DIR, \"tsd_trial.csv\"))\n",
    "\n",
    "validationset[\"text\"] = validationset[\"text\"].apply(str.lower)\n",
    "validationset[\"spans\"] = deserialize_spans(validationset[\"spans\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e202b9",
   "metadata": {},
   "source": [
    "Let us isolate a document of the validation set, for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea144933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump said, in as many words, that mexicans were rapists and drug dealers.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationset[\"text\"].loc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc2f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = RandomSequenceLabeller()\n",
    "\n",
    "pred = random_model.predict(doc=validationset[\"text\"].loc[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0f92e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump said, in as many words, that mexicans were rapists and drug dealers.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[0, 4, 5, 6, 11, 14, 15, 17, 18, 20, 21, 24, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 48, 53, 54, 55, 57, 60, 61, 62, 63, 64, 65, 71, 72]\n"
     ]
    }
   ],
   "source": [
    "print(validationset[\"text\"].loc[11])\n",
    "print(\"-\" * 100)\n",
    "print(str(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "529ee4ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(pred, gold=validationset[\"spans\"].loc[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "580ab26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (690, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>random_predictions</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>because he's a moron and a bigot. it's not any more complicated than that.</td>\n",
       "      <td>[0, 2, 6, 8, 9, 12, 13, 17, 18, 22, 23, 24, 25, 27, 28, 29, 31, 35, 36, 38, 40, 41, 43, 44, 46, 47, 48, 49, 53, 54, 55, 58, 59, 63, 64, 67, 69, 72, 73]</td>\n",
       "      <td>0.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>how about we stop protecting idiots and let nature add some bleach to the gene pool. we can always submit their names for the darwin awards.</td>\n",
       "      <td>[2, 3, 5, 9, 13, 15, 16, 19, 22, 23, 25, 26, 32, 33, 34, 38, 45, 47, 48, 50, 51, 52, 53, 54, 61, 63, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 81, 84, 85, 88, 90, 91, 93, 94, 95, 97, 100, 103, 106, 107, 111, 112, 113, 116, 117, 118, 119, 120, 122, 124, 125, 129, 131, 132, 134, 137, 138]</td>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>if people  were  smart, they would  boycott this  inept  airline,  but   they  are  not  smart,  so   rogue  businesses  like  this  one,   still thrive   taking the idiots  for  a ride...</td>\n",
       "      <td>[3, 4, 6, 7, 11, 12, 13, 14, 15, 19, 20, 21, 22, 26, 27, 29, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 46, 47, 49, 52, 57, 58, 60, 62, 63, 64, 66, 68, 72, 74, 75, 77, 79, 81, 82, 83, 84, 85, 88, 91, 92, 100, 101, 102, 103, 105, 109, 110, 115, 116, 119, 120, 122, 123, 124, 130, 133, 135, 138, 140, 141, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 176, 179, 180, 183, 187]</td>\n",
       "      <td>0.077670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>trump claimed that russia will never invade the ukraine, when russia already has - how stupid can people be?</td>\n",
       "      <td>[0, 1, 2, 3, 7, 8, 9, 11, 12, 13, 19, 24, 27, 29, 36, 38, 39, 43, 44, 46, 47, 48, 49, 50, 55, 56, 58, 59, 61, 62, 64, 65, 69, 70, 72, 74, 75, 77, 78, 79, 81, 82, 86, 88, 89, 91, 92, 93, 94, 96, 97, 99, 100, 103, 105, 106]</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>as long as your willing to pay a lot more for products you buy, then fine.\\nbut you better not be going to costco and walmart to buy stuff because it's cheaper.\\nif so, we get to call you a hypocritical wanker.</td>\n",
       "      <td>[0, 3, 6, 9, 11, 12, 15, 17, 19, 20, 21, 23, 26, 28, 30, 32, 34, 40, 41, 45, 46, 47, 54, 56, 57, 58, 60, 62, 63, 68, 70, 73, 76, 78, 80, 81, 82, 84, 87, 88, 90, 91, 92, 93, 96, 102, 105, 106, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 122, 123, 126, 127, 128, 129, 137, 138, 139, 140, 141, 142, 145, 147, 148, 150, 151, 156, 157, 159, 161, 162, 163, 167, 169, 170, 171, 172, 176, 177, 178, 180, 181, 183, 185, 186, 189, 190, 192, 193, 196, 198, ...]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                          because he's a moron and a bigot. it's not any more complicated than that.   \n",
       "1                                                                        how about we stop protecting idiots and let nature add some bleach to the gene pool. we can always submit their names for the darwin awards.   \n",
       "2                        if people  were  smart, they would  boycott this  inept  airline,  but   they  are  not  smart,  so   rogue  businesses  like  this  one,   still thrive   taking the idiots  for  a ride...   \n",
       "3                                                                                                        trump claimed that russia will never invade the ukraine, when russia already has - how stupid can people be?   \n",
       "4  as long as your willing to pay a lot more for products you buy, then fine.\\nbut you better not be going to costco and walmart to buy stuff because it's cheaper.\\nif so, we get to call you a hypocritical wanker.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                         random_predictions  \\\n",
       "0                                                                                                                                                                                                                                                                                                                   [0, 2, 6, 8, 9, 12, 13, 17, 18, 22, 23, 24, 25, 27, 28, 29, 31, 35, 36, 38, 40, 41, 43, 44, 46, 47, 48, 49, 53, 54, 55, 58, 59, 63, 64, 67, 69, 72, 73]   \n",
       "1                                                                                                                                                                         [2, 3, 5, 9, 13, 15, 16, 19, 22, 23, 25, 26, 32, 33, 34, 38, 45, 47, 48, 50, 51, 52, 53, 54, 61, 63, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 81, 84, 85, 88, 90, 91, 93, 94, 95, 97, 100, 103, 106, 107, 111, 112, 113, 116, 117, 118, 119, 120, 122, 124, 125, 129, 131, 132, 134, 137, 138]   \n",
       "2                             [3, 4, 6, 7, 11, 12, 13, 14, 15, 19, 20, 21, 22, 26, 27, 29, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 46, 47, 49, 52, 57, 58, 60, 62, 63, 64, 66, 68, 72, 74, 75, 77, 79, 81, 82, 83, 84, 85, 88, 91, 92, 100, 101, 102, 103, 105, 109, 110, 115, 116, 119, 120, 122, 123, 124, 130, 133, 135, 138, 140, 141, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 167, 168, 169, 170, 176, 179, 180, 183, 187]   \n",
       "3                                                                                                                                                                                                                                             [0, 1, 2, 3, 7, 8, 9, 11, 12, 13, 19, 24, 27, 29, 36, 38, 39, 43, 44, 46, 47, 48, 49, 50, 55, 56, 58, 59, 61, 62, 64, 65, 69, 70, 72, 74, 75, 77, 78, 79, 81, 82, 86, 88, 89, 91, 92, 93, 94, 96, 97, 99, 100, 103, 105, 106]   \n",
       "4  [0, 3, 6, 9, 11, 12, 15, 17, 19, 20, 21, 23, 26, 28, 30, 32, 34, 40, 41, 45, 46, 47, 54, 56, 57, 58, 60, 62, 63, 68, 70, 73, 76, 78, 80, 81, 82, 84, 87, 88, 90, 91, 92, 93, 96, 102, 105, 106, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 122, 123, 126, 127, 128, 129, 137, 138, 139, 140, 141, 142, 145, 147, 148, 150, 151, 156, 157, 159, 161, 162, 163, 167, 169, 170, 171, 172, 176, 177, 178, 180, 181, 183, 185, 186, 189, 190, 192, 193, 196, 198, ...]   \n",
       "\n",
       "   f1_score  \n",
       "0  0.244898  \n",
       "1  0.081081  \n",
       "2  0.077670  \n",
       "3  0.129032  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now for the whole validation dataset\n",
    "valset = validationset.copy()\n",
    "\n",
    "valset[\"random_predictions\"] = valset[\"text\"].apply(random_model.predict)\n",
    "valset[\"f1_score\"] = valset.apply(\n",
    "    lambda s: f1(s.random_predictions, gold=s.spans), axis=1\n",
    ")\n",
    "\n",
    "inspect_df(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae66f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1798930647084133"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valset[\"f1_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd4f19c",
   "metadata": {},
   "source": [
    "So, averaging over the validation dataset, our random classifier achieves an F1 score of approx. `17%`.\n",
    "\n",
    "We consider this a baseline performance for this task. Let's improve on this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd302c4",
   "metadata": {},
   "source": [
    "## As a Downstream Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db30bb",
   "metadata": {},
   "source": [
    "We will begin with some pre-trained model, that can be fine-tuned to our task,to develop a better feel for the problem.\n",
    "\n",
    "We will utilize a [transformer](https://huggingface.co/google/mobilebert-uncased) MobileBERT model and its respective tokenizer for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4f5d1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd506fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicSpansDataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        return {\n",
    "            \"tokens\": torch.tensor(row[\"pad_tokenized_text\"]).long(),\n",
    "            \"attention_mask\": torch.tensor(row[\"pad_attention_mask\"]).long(),\n",
    "            \"labels\": torch.tensor(row[\"pad_encoded_span\"]).long(),\n",
    "            \"pad_offset_mapping\": torch.tensor(row[\"pad_offset_mapping\"]).long(),\n",
    "            \"pad_span\": torch.tensor(row[\"pad_raw_spans\"]).long(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a6a89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicSpansDataModule(LightningDataModule):\n",
    "    def __init__(self, tokenizer, batch_size: int = 32, max_len: int = 512):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = os.path.join(PROJECT_ROOT, \"data\")\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_len\n",
    "        self.trainset = None\n",
    "        self.validationset = None\n",
    "\n",
    "    def prepare_data(self, *args, **kwargs) -> None:\n",
    "\n",
    "        # load data into memory\n",
    "        trainset = pd.read_csv(os.path.join(self.data_dir, \"tsd_train.csv\"))\n",
    "        validationset = pd.read_csv(os.path.join(self.data_dir, \"tsd_trial.csv\"))\n",
    "\n",
    "        # preprocessing\n",
    "        self.trainset = self._preprocess(trainset)\n",
    "        self.validationset = self._preprocess(validationset)\n",
    "\n",
    "    def _preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        df[\"spans\"] = deserialize_spans(df[\"spans\"])\n",
    "\n",
    "        docs, spans = df[\"text\"].values, df[\"spans\"]\n",
    "\n",
    "        data = []\n",
    "        for sentence, span in tqdm(zip(docs, spans), total=len(docs)):\n",
    "\n",
    "            encoded = self.tokenizer(\n",
    "                sentence,\n",
    "                add_special_tokens=True,\n",
    "                padding=\"max_length\",\n",
    "                return_offsets_mapping=True,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "\n",
    "            encoded_span = np.array(\n",
    "                [\n",
    "                    1 if any((left <= chr_pos < right for chr_pos in span)) else 0\n",
    "                    for left, right in encoded[\"offset_mapping\"]\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            tokens = np.array(encoded.encodings[0].tokens)\n",
    "\n",
    "            padded_span = np.pad(\n",
    "                span,\n",
    "                mode=\"constant\",\n",
    "                pad_width=(0, 1024 - len(span)),\n",
    "                constant_values=-1,\n",
    "            )\n",
    "\n",
    "            data.append(\n",
    "                [\n",
    "                    sentence,\n",
    "                    span,\n",
    "                    padded_span,\n",
    "                    encoded[\"input_ids\"],\n",
    "                    encoded[\"attention_mask\"],\n",
    "                    encoded[\"offset_mapping\"],\n",
    "                    encoded_span,\n",
    "                    tokens,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            data,\n",
    "            columns=[\n",
    "                \"raw_text\",\n",
    "                \"raw_spans\",\n",
    "                \"pad_raw_spans\",\n",
    "                \"pad_tokenized_text\",\n",
    "                \"pad_attention_mask\",\n",
    "                \"pad_offset_mapping\",\n",
    "                \"pad_encoded_span\",\n",
    "                \"pad_tokens\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> data.DataLoader:\n",
    "\n",
    "        return data.DataLoader(\n",
    "            ToxicSpansDataset(self.trainset), num_workers=8, batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> data.DataLoader:\n",
    "\n",
    "        return data.DataLoader(\n",
    "            ToxicSpansDataset(self.validationset),\n",
    "            num_workers=8,\n",
    "            batch_size=self.batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52827cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(tokenizer, text: str, max_sentence_length: int, spans=None) -> tuple:\n",
    "\n",
    "    encoded = tokenizer(text, add_special_tokens=True, return_offsets_mapping=True)\n",
    "\n",
    "    sentences_offsets = [\n",
    "        offset[1]\n",
    "        for input_ids, offset in zip(encoded[\"input_ids\"], encoded[\"offset_mapping\"])\n",
    "        if input_ids == 1012\n",
    "    ]\n",
    "\n",
    "    if len(sentences_offsets) == 0 or len(text) - sentences_offsets[-1] > 0:\n",
    "        sentences_offsets.append(len(text))\n",
    "\n",
    "    new_split = [0]\n",
    "    for split_offset_id in range(len(sentences_offsets) - 1):\n",
    "        if sentences_offsets[split_offset_id + 1] - new_split[-1] > max_sentence_length:\n",
    "            new_split.append(sentences_offsets[split_offset_id])\n",
    "\n",
    "    if not new_split[-1] == sentences_offsets[-1]:\n",
    "        new_split.append(sentences_offsets[-1])\n",
    "\n",
    "    if spans:\n",
    "        spans_vector = [i in row[\"spans\"] for i in range(len(row[\"text\"]))]\n",
    "\n",
    "    texts, new_spans, offsets = [], [], []\n",
    "    for offset_id in range(len(new_split) - 1):\n",
    "        a, b = new_split[offset_id], new_split[offset_id + 1]\n",
    "        texts.append(text[a:b])\n",
    "        offsets.append(new_split[offset_id])\n",
    "\n",
    "        if spans:\n",
    "            spans_in_subtext = [\n",
    "                idx for idx, is_true in enumerate(spans_vector[a:b]) if is_true\n",
    "            ]\n",
    "            new_spans.append(spans_in_subtext)\n",
    "\n",
    "    if not spans:\n",
    "        new_spans = [[] for _ in range(len(offsets))]\n",
    "\n",
    "    return texts, offsets, new_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55d2041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicSpansModule(LightningModule):\n",
    "    def __init__(self, model=None, *args, **kwargs):\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        \"\"\"Use for inference only.\"\"\"\n",
    "        pred = self.model(*args, **kwargs)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def training_step(self, batch, batch_nb) -> dict:\n",
    "        \"\"\"The full training loop.\"\"\"\n",
    "        outputs = self(\n",
    "            batch[\"tokens\"],\n",
    "            token_type_ids=None,\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"],\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss.item(), logger=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb) -> None:\n",
    "        \"\"\"The full validation loop.\"\"\"\n",
    "        outputs = self(\n",
    "            batch[\"tokens\"],\n",
    "            token_type_ids=None,\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"],\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        self.log(\"val_loss\", loss.item(), logger=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "\n",
    "        # get predictions from logits\n",
    "        y_pred = np.argmax(logits, axis=-1).astype(int)\n",
    "        # also fetch ground truth\n",
    "        y_true = batch[\"labels\"].to(\"cpu\").numpy().astype(int)\n",
    "\n",
    "        pad_span = batch[\"pad_span\"].to(\"cpu\").numpy().astype(int)\n",
    "        pad_offset_mapping = batch[\"pad_offset_mapping\"].to(\"cpu\").numpy().astype(int)\n",
    "\n",
    "        spanwise_f1 = []\n",
    "\n",
    "        for i in range(len(y_true)):\n",
    "\n",
    "            # remove '-1' padding introduced in ToxicSpansDataModule#_preprocessing\n",
    "            true_spans = list(set(pad_span[i]) - {-1})\n",
    "\n",
    "            predicted_offsets = pad_offset_mapping[i][y_pred[i].astype(bool)]\n",
    "            predicted_spans = [\n",
    "                j for offset in predicted_offsets for j in range(offset[0], offset[1])\n",
    "            ]\n",
    "\n",
    "            f1_score = f1(predictions=predicted_spans, gold=true_spans)\n",
    "            spanwise_f1.append(f1_score)\n",
    "\n",
    "        self.log(\n",
    "            \"spanwise_f1\",\n",
    "            np.mean(np.array(spanwise_f1)),\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "\n",
    "    def predict_data(self, data: pd.DataFrame, tokenizer) -> pd.DataFrame:\n",
    "\n",
    "        self.model.eval()\n",
    "        self.model.cuda()\n",
    "\n",
    "        result = pd.DataFrame({\"spans\": pd.Series(np.zeros(len(data))).values})\n",
    "\n",
    "        for i, row in tqdm(data.iterrows(), total=len(data)):\n",
    "            texts, offsets, _ = split_sentence(\n",
    "                tokenizer, row[\"text\"], max_sentence_length=1000\n",
    "            )\n",
    "\n",
    "            predicted_spans = list()\n",
    "            for text, offset in zip(texts, offsets):\n",
    "                encoded = tokenizer(\n",
    "                    text,\n",
    "                    add_special_tokens=True,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    eturn_offsets_mapping=True,\n",
    "                    max_length=sentence_length,\n",
    "                )\n",
    "                item = {\n",
    "                    k: torch.tensor(v).unsqueeze(0).long().cuda()\n",
    "                    for k, v in encoded.items()\n",
    "                }\n",
    "\n",
    "                output = self(\n",
    "                    item[\"input_ids\"],\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=item[\"attention_mask\"],\n",
    "                )\n",
    "                logits = output.logits.detach().cpu().numpy()\n",
    "                y_pred = np.argmax(logits, axis=-1).squeeze().astype(int)\n",
    "                predicted_offsets = np.array(encoded[\"offset_mapping\"])[\n",
    "                    y_pred.astype(bool)\n",
    "                ]\n",
    "                spans = [\n",
    "                    i\n",
    "                    for offset in predicted_offsets\n",
    "                    for i in range(offset[0], offset[1])\n",
    "                ]\n",
    "                predicted_spans.extend(list(np.array(spans) + offset))\n",
    "\n",
    "            result.loc[i, \"spans\"] = str(predicted_spans)\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self) -> dict:\n",
    "        \"\"\"Define optimizers and LR schedulers.\"\"\"\n",
    "        optimizer = AdamW(self.model.parameters(), lr=2e-5, eps=1e-8)\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3359d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs: int = 10, batch_size: int = 3):\n",
    "\n",
    "    seed_everything(42)\n",
    "\n",
    "    # define model checkpoints\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        dirpath=\"checkpoints/\",\n",
    "        save_weights_only=True,\n",
    "        save_top_k=3,\n",
    "        monitor=\"spanwise_f1\",\n",
    "        mode=\"max\",\n",
    "        every_n_epochs=1,\n",
    "    )\n",
    "\n",
    "    # define training process callbacks\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"spanwise_f1\", mode=\"max\", min_delta=0.01, patience=10, verbose=True\n",
    "    )\n",
    "\n",
    "    callbacks = [model_checkpoint, early_stop_callback]\n",
    "\n",
    "    # use tokenizer from MobileBERT pre-trained model\n",
    "    tokenizer = MobileBertTokenizerFast.from_pretrained(\n",
    "        \"google/mobilebert-uncased\", do_lower_case=True\n",
    "    )\n",
    "\n",
    "    base = MobileBertForTokenClassification.from_pretrained(\n",
    "        \"google/mobilebert-uncased\",\n",
    "        num_labels=2,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "    )\n",
    "\n",
    "    # instantiate a data module\n",
    "    datamodule = ToxicSpansDataModule(tokenizer=tokenizer, batch_size=batch_size)\n",
    "    # instantiate a trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=epochs, callbacks=callbacks, gpus=1, deterministic=True\n",
    "    )\n",
    "    \n",
    "    model = ToxicSpansModule(model=base)\n",
    "    \n",
    "    # train the model\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    \n",
    "    # fetch the held-out dataset\n",
    "    testset = pd.read_csv(os.path.join(DATA_DIR, \"tsd_test.csv\"))\n",
    "    \n",
    "    # make predictions\n",
    "    predict(model, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de76ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, predictions: pd.DataFrame) -> None:\n",
    "    \"\"\"Special method in order to predict on test dataset.\"\"\"\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    # use tokenizer from MobileBERT pre-trained model\n",
    "    tokenizer = MobileBertTokenizerFast.from_pretrained(\n",
    "        \"google/mobilebert-uncased\", do_lower_case=True\n",
    "    )\n",
    "\n",
    "    result = pd.DataFrame({\"spans\": pd.Series(np.zeros(len(predictions))).values})\n",
    "\n",
    "    for i, row in tqdm(predictions.iterrows(), total=len(predictions)):\n",
    "\n",
    "        texts, offsets, _ = split_sentence(\n",
    "            tokenizer, row[\"text\"], max_sentence_length=512\n",
    "        )\n",
    "\n",
    "        predicted_spans = []\n",
    "        for text, offset in zip(texts, offsets):\n",
    "\n",
    "            encoded = tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_offsets_mapping=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "\n",
    "            item = {\n",
    "                k: torch.tensor(v).unsqueeze(0).long().cuda()\n",
    "                for k, v in encoded.items()\n",
    "            }\n",
    "\n",
    "            output = model(\n",
    "                item[\"input_ids\"],\n",
    "                token_type_ids=None,\n",
    "                attention_mask=item[\"attention_mask\"],\n",
    "            )\n",
    "            logits = output.logits.detach().cpu().numpy()\n",
    "            y_pred = np.argmax(logits, axis=-1).squeeze().astype(int)\n",
    "            predicted_offsets = np.array(encoded[\"offset_mapping\"])[y_pred.astype(bool)]\n",
    "            spans = [\n",
    "                i for offset in predicted_offsets for i in range(offset[0], offset[1])\n",
    "            ]\n",
    "\n",
    "            predicted_spans.extend(list(np.array(spans) + offset))\n",
    "\n",
    "        result.loc[i, \"spans\"] = str(predicted_spans)\n",
    "\n",
    "    result.to_csv(\n",
    "        \"spans-pred.txt\",\n",
    "        header=False,\n",
    "        sep=\"\\t\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "        escapechar=\"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d387c",
   "metadata": {},
   "source": [
    "We will now fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37c5c39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing MobileBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MobileBertForTokenClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "100%|| 7939/7939 [00:07<00:00, 996.81it/s]\n",
      "100%|| 690/690 [00:00<00:00, 1106.12it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Missing logger folder: /home/iantonopoulos/projects/toxic-spans-detection/notebooks/lightning_logs\n",
      "\n",
      "  | Name  | Type                             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model | MobileBertForTokenClassification | 24.6 M\n",
      "-----------------------------------------------------------\n",
      "24.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.6 M    Total params\n",
      "98.332    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2842831c354bd188cf4989aa69ba59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric spanwise_f1 improved. New best score: 0.462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric spanwise_f1 improved by 0.087 >= min_delta = 0.01. New best score: 0.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric spanwise_f1 improved by 0.048 >= min_delta = 0.01. New best score: 0.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric spanwise_f1 improved by 0.026 >= min_delta = 0.01. New best score: 0.622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric spanwise_f1 improved by 0.014 >= min_delta = 0.01. New best score: 0.636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-05.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-06.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Epoch    10: reducing learning rate of group 0 to 2.5000e-06.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    epochs=10, batch_size=3\n",
    ")  # batch size > 3 yielded CUDA out of memory error in my (poor) setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00810de8",
   "metadata": {},
   "source": [
    "After 10 epochs, the MobileBERT classifier yields a spanwise f1 score of `63.6%` on epoch `#6`. This seems to be a drastic improvement over the baseline performance of `~17%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing MobileBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MobileBertForTokenClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "100%|| 7939/7939 [00:07<00:00, 1005.64it/s]\n",
      "100%|| 690/690 [00:00<00:00, 1061.31it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                             | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model | MobileBertForTokenClassification | 24.6 M\n",
      "-----------------------------------------------------------\n",
      "24.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.6 M    Total params\n",
      "98.332    Total estimated model params size (MB)\n",
      "/home/iantonopoulos/.cache/pypoetry/virtualenvs/toxic-spans-detection-aBNDteoa-py3.8/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/iantonopoulos/projects/toxic-spans-detection/notebooks/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dab34ac8d5f4e4996281aa10278dd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    epochs=1, batch_size=1\n",
    ")  # batch size > 3 yielded CUDA out of memory error in my (poor) setup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
